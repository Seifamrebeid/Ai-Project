{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ec3794",
   "metadata": {},
   "source": [
    "# COVID-19 Prediction Model\n",
    "\n",
    "This notebook implements an end-to-end machine learning pipeline for COVID-19 hospitalization prediction:\n",
    "- **Part 1**: Data cleaning and preprocessing\n",
    "- **Part 2**: Exploratory data analysis\n",
    "- **Part 3**: Model training and evaluation\n",
    "- **Part 4**: Advanced validation and deployment\n",
    "\n",
    "**Note**: See `documentation.md` for detailed methodology and design decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40865699",
   "metadata": {},
   "source": [
    "# PART 1: DATA CLEANING & PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f91489",
   "metadata": {},
   "source": [
    "## Load Dataset and Dependencies\n",
    "\n",
    "\n",
    "Import the core libraries needed for data manipulation and numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe14598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36236ab",
   "metadata": {},
   "source": [
    "Load dataset with configurable sample size for faster processing:\n",
    "\n",
    "\n",
    "The `SAMPLE_SIZE` variable controls how many rows to load. Using a smaller sample (like 400K instead of the full 700K) significantly reduces processing time while maintaining reasonable accuracy. Set to `None` to load the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bbc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 400000  # Default: 400K rows for balanced speed/accuracy (~4-5 minutes)\n",
    "\n",
    "if SAMPLE_SIZE is not None:\n",
    "    df = pd.read_csv('../data/Covid_Data.csv', nrows=SAMPLE_SIZE)\n",
    "    print(f\"Loading sample: {SAMPLE_SIZE:,} rows\")\n",
    "else:\n",
    "    df = pd.read_csv('../data/Covid_Data.csv')\n",
    "    print(\"Loading full dataset...\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]:,}, Columns: {df.shape[1]}\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852429cf",
   "metadata": {},
   "source": [
    "## Remove Data Leakage\n",
    "\n",
    "Remove `DATE_DIED` - this is a post-outcome variable unavailable at prediction time:\n",
    "\n",
    "\n",
    "**Why this matters:** If we kept DATE_DIED, the model would learn that \"having a death date means severe COVID\", but this information only exists AFTER the outcome occurs. In real-world prediction, we need to predict before knowing if someone will die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86196842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"DATE_DIED\"], inplace=True)\n",
    "\n",
    "print(\"After dropping DATE_DIED:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885251cf",
   "metadata": {},
   "source": [
    "## Remove Demographic Bias\n",
    "\n",
    "Remove `SEX` to focus on medical symptoms only:\n",
    "\n",
    "\n",
    "**Why this matters:** While sex might correlate with COVID outcomes, including it could introduce bias in predictions. We want the model to focus purely on medical symptoms and conditions rather than demographic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"SEX\"], inplace=True)\n",
    "\n",
    "print(\"After dropping SEX:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b48a2e",
   "metadata": {},
   "source": [
    "## Encode Hospitalization Status\n",
    "\n",
    "Rename and re-encode PATIENT_TYPE as HOSPITALIZED (1=hospitalized, 0=outpatient):\n",
    "\n",
    "\n",
    "**What this does:** Converts the original encoding (1=outpatient, 2=hospitalized) to a more intuitive binary format (0=outpatient, 1=hospitalized) where 1 represents the more severe condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "df.rename(columns={\"PATIENT_TYPE\": \"HOSPITALIZED\"}, inplace=True)\n",
    "\n",
    "# Re-encode values\n",
    "df[\"HOSPITALIZED\"] = df[\"HOSPITALIZED\"].replace({1: 0, 2: 1})\n",
    "\n",
    "print(df[\"HOSPITALIZED\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e17b7",
   "metadata": {},
   "source": [
    "## Filter Valid Classifications\n",
    "\n",
    "Keep only valid COVID classification codes (1-7):\n",
    "\n",
    "\n",
    "**What this does:** Removes records with classification codes 97, 98, 99 which represent \"unknown\", \"not applicable\", or \"missing\" values. These would add noise to the model and reduce prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a37509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"CLASIFFICATION_FINAL\"].between(1, 7)]\n",
    "\n",
    "print(\"After filtering CLASIFFICATION_FINAL:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238f4e2",
   "metadata": {},
   "source": [
    "## Create Binary Target Variable\n",
    "\n",
    "Create `covid` target: classes 1-3 → 1 (positive), classes 4-7 → 0 (negative):\n",
    "\n",
    "\n",
    "**What this does:** Converts the multi-class classification problem into binary classification. Classes 1-3 represent confirmed COVID cases, while 4-7 represent negative or non-COVID cases. This simplifies the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"covid\"] = df[\"CLASIFFICATION_FINAL\"].apply(\n",
    "    lambda x: 1 if x in [1, 2, 3] else 0\n",
    ")\n",
    "\n",
    "print(df[\"covid\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7b3b5",
   "metadata": {},
   "source": [
    "## Define Binary Features\n",
    "\n",
    "List all binary medical condition features for encoding:\n",
    "\n",
    "\n",
    "**What this does:** Creates a list of all medical condition columns that need binary encoding. These represent presence/absence of various health conditions and symptoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc276482",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [\n",
    "    \"USMER\", \"HOSPITALIZED\", \"INTUBED\", \"PNEUMONIA\",\n",
    "    \"PREGNANT\", \"DIABETES\", \"COPD\", \"ASTHMA\", \"INMSUPR\",\n",
    "    \"HIPERTENSION\", \"OTHER_DISEASE\", \"CARDIOVASCULAR\",\n",
    "    \"OBESITY\", \"RENAL_CHRONIC\", \"TOBACCO\", \"ICU\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e66dc",
   "metadata": {},
   "source": [
    "## Filter Binary Features\n",
    "\n",
    "Keep only rows with valid binary values (1 or 2) for all medical features:\n",
    "\n",
    "\n",
    "**What this does:** Removes rows containing missing or invalid values (97, 98, 99) in any medical condition column. This ensures data quality by keeping only complete, valid records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    df = df[df[col].isin([1, 2])]\n",
    "\n",
    "print(\"After strict binary filtering:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4128f0",
   "metadata": {},
   "source": [
    "## Standardize Binary Encoding\n",
    "\n",
    "Convert all binary features to 0/1 format (1→1, 2→0):\n",
    "\n",
    "\n",
    "**What this does:** Transforms the original encoding (1=yes, 2=no) to standard binary format (1=yes, 0=no). Machine learning models work better with 0/1 encoding as it's mathematically cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[binary_cols] = df[binary_cols].replace({1: 1, 2: 0})\n",
    "\n",
    "print(\"Binary encoding completed (1 → 1, 2 → 0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5ddd5",
   "metadata": {},
   "source": [
    "## Clean Age Column\n",
    "\n",
    "Convert AGE to numeric and filter valid range (0-120):\n",
    "\n",
    "\n",
    "**What this does:** Ensures age values are numeric and biologically plausible. Any non-numeric values are converted to NaN (coercion), and ages outside 0-120 range are filtered out as they're likely data entry errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AGE\"] = pd.to_numeric(df[\"AGE\"], errors=\"coerce\")\n",
    "df = df[(df[\"AGE\"] >= 0) & (df[\"AGE\"] <= 120)]\n",
    "\n",
    "print(\"After AGE cleaning:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffb733",
   "metadata": {},
   "source": [
    "## Remove Classification Column\n",
    "\n",
    "Drop CLASIFFICATION_FINAL after creating target variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CLASIFFICATION_FINAL\"], inplace=True)\n",
    "\n",
    "print(\"Final cleaned dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ecd0a",
   "metadata": {},
   "source": [
    "## Validate Data Quality\n",
    "\n",
    "Verify all binary columns contain only 0 or 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233618e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all binary columns contain only 0 or 1\n",
    "for col in binary_cols:\n",
    "    assert set(df[col].unique()).issubset({0, 1})\n",
    "\n",
    "print(\"All binary columns are clean (0/1 only)\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11850313",
   "metadata": {},
   "source": [
    "# PART 2: EXPLORATORY DATA ANALYSIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41340a4b",
   "metadata": {},
   "source": [
    "## Import ML Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752da36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix, \n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752da36d",
   "metadata": {},
   "source": [
    "## Visualize Target Distribution\n",
    "\n",
    "Plot COVID-19 case distribution (count and percentage):\n",
    "\n",
    "\n",
    "**What this shows:** The balance between COVID positive and negative cases in our dataset. Understanding class distribution helps identify if we have imbalanced data, which could affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "covid_counts = df[\"covid\"].value_counts()\n",
    "axes[0].bar(['COVID Negative', 'COVID Positive'], covid_counts.values, \n",
    "            color=['lightgreen', 'lightcoral'], edgecolor='black')\n",
    "axes[0].set_title('COVID-19 Distribution (Count)', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylabel('Number of Patients')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add counts on bars\n",
    "for i, v in enumerate(covid_counts.values):\n",
    "    axes[0].text(i, v + 100, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(covid_counts.values, labels=['COVID Negative', 'COVID Positive'], \n",
    "            autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'], \n",
    "            startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('COVID-19 Distribution (%)', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCOVID Distribution:\")\n",
    "print(f\"Negative: {covid_counts[0]:,} ({covid_counts[0]/len(df)*100:.2f}%)\")\n",
    "print(f\"Positive: {covid_counts[1]:,} ({covid_counts[1]/len(df)*100:.2f}%)\")\n",
    "print(f\"Total: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bd808",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "Generate correlation matrix and identify top features correlated with COVID:\n",
    "\n",
    "\n",
    "**What this shows:** How strongly each medical feature correlates with COVID status. Positive correlations (closer to +1) mean the feature increases with COVID presence, negative correlations (closer to -1) mean it decreases. Features with strong correlations are likely important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebf375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, \n",
    "            center=0, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix - All Medical Features', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target\n",
    "print(f\"\\nTop features correlated with COVID:\")\n",
    "target_corr = df.corr()[\"covid\"].sort_values(ascending=False)\n",
    "for feat, corr in target_corr.items():\n",
    "    if feat != \"covid\":\n",
    "        print(f\"{feat:20s}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29a468",
   "metadata": {},
   "source": [
    "## Feature Distributions\n",
    "\n",
    "Visualize distribution of all binary medical conditions:\n",
    "\n",
    "\n",
    "**What this shows:** The frequency of each medical condition in the dataset. This helps identify common vs rare conditions and ensures we have sufficient data for each feature to make meaningful predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55934c",
   "metadata": {},
   "source": [
    "## Age Distribution Analysis\n",
    "\n",
    "Compare age distributions between COVID positive and negative cases:\n",
    "\n",
    "\n",
    "**What this shows:** How age distribution differs between COVID positive and negative patients. This visualization reveals if certain age groups are more susceptible to COVID, which is valuable medical insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58291594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary features distribution\n",
    "binary_features = [col for col in df.columns if col != 'covid' and col != 'AGE' and col not in ['USMER', 'MEDICAL_UNIT']]\n",
    "\n",
    "n_features = len(binary_features)\n",
    "n_cols = 4\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(binary_features):\n",
    "    counts = df[feature].value_counts().sort_index()\n",
    "    axes[idx].bar(['No', 'Yes'], counts.values if len(counts) == 2 else [counts.get(0, 0), counts.get(1, 0)],\n",
    "                  color=['lightblue', 'salmon'], edgecolor='black')\n",
    "    axes[idx].set_title(f'{feature}', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_features, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Distribution of Medical Conditions', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Age distribution by COVID status\n",
    "for status in [0, 1]:\n",
    "    label = 'COVID Negative' if status == 0 else 'COVID Positive'\n",
    "    color = 'lightgreen' if status == 0 else 'lightcoral'\n",
    "    axes[0].hist(df[df['covid'] == status]['AGE'], bins=30, alpha=0.7, \n",
    "                 label=label, color=color, edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Age', fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontweight='bold')\n",
    "axes[0].set_title('Age Distribution by COVID Status', fontweight='bold', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "age_data = [df[df['covid'] == 0]['AGE'], df[df['covid'] == 1]['AGE']]\n",
    "bp = axes[1].boxplot(age_data, labels=['COVID Negative', 'COVID Positive'], \n",
    "                      patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], ['lightgreen', 'lightcoral']):\n",
    "    patch.set_facecolor(color)\n",
    "axes[1].set_ylabel('Age', fontweight='bold')\n",
    "axes[1].set_title('Age Distribution (Box Plot)', fontweight='bold', fontsize=14)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Age statistics\n",
    "print(f\"\\nAge Statistics by COVID Status:\")\n",
    "for status in [0, 1]:\n",
    "    label = 'Negative' if status == 0 else 'Positive'\n",
    "    age_data = df[df['covid'] == status]['AGE']\n",
    "    print(f\"\\n{label}: Mean={age_data.mean():.1f}, Median={age_data.median():.1f}, Std={age_data.std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2045c65",
   "metadata": {},
   "source": [
    "# PART 3: MODEL TRAINING & EVALUATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a0dc7",
   "metadata": {},
   "source": [
    "## Prepare Features and Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"covid\"])\n",
    "y = df[\"covid\"]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ed740",
   "metadata": {},
   "source": [
    "## Split Data (Stratified)\n",
    "\n",
    "80/20 train-test split maintaining class distribution:\n",
    "\n",
    "\n",
    "**What this does:** Divides data into 80% for training models and 20% for testing. Stratification ensures both sets have the same proportion of COVID positive/negative cases, preventing bias in evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stratified split to maintain class distribution in train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c349df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply StandardScaler (0 mean, 1 std deviation)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "print(f\"AGE range: [{X_train['AGE'].min():.0f}, {X_train['AGE'].max():.0f}] -> [{X_train_scaled[:, X_train.columns.get_loc('AGE')].min():.2f}, {X_train_scaled[:, X_train.columns.get_loc('AGE')].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a93a22",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Apply StandardScaler for distance-based algorithms (improves KNN and LogReg):\n",
    "\n",
    "\n",
    "**What this does:** Transforms features to have mean=0 and standard deviation=1. This is crucial for distance-based algorithms (KNN, Logistic Regression) because features with larger ranges would otherwise dominate the calculations. For example, AGE (0-120) would overpower binary features (0-1) without scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85175251",
   "metadata": {},
   "source": [
    "## Define Evaluation Function\n",
    "\n",
    "\n",
    "**What this does:** Creates a reusable function to calculate key performance metrics: Accuracy (% correct), Precision (% of positive predictions that are correct), Recall (% of actual positives detected), and F1-Score (harmonic mean of precision and recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85583f3",
   "metadata": {},
   "source": [
    "## Train Model 1: Logistic Regression\n",
    "\n",
    "\n",
    "**What this does:** Trains a linear classification model that predicts probabilities using a logistic function. It's fast, interpretable, and works well as a baseline. Uses scaled data because it's sensitive to feature magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ce1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)  # Use scaled data\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)  # Use scaled test data\n",
    "\n",
    "print(\"Logistic Regression trained with scaled features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65960da5",
   "metadata": {},
   "source": [
    "## Train Model 2: Decision Tree (Regularized)\n",
    "\n",
    "Regularization prevents overfitting with max_depth, min_samples constraints:\n",
    "\n",
    "\n",
    "**What this does:** Trains a tree-based model that makes decisions using if-then rules. Regularization parameters (max_depth, min_samples) prevent the tree from becoming too complex and memorizing training data. Class weights handle imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regularization to prevent overfitting\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=8,               # Limit tree depth\n",
    "    min_samples_split=20,      # Require more samples to split\n",
    "    min_samples_leaf=10,       # Require more samples in leaf nodes\n",
    "    random_state=42,\n",
    "    class_weight='balanced'    # Handle class imbalance\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree trained with regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364534a",
   "metadata": {},
   "source": [
    "## Train Model 3: Random Forest (Regularized)\n",
    "\n",
    "Reduced trees and added constraints to improve generalization:\n",
    "\n",
    "\n",
    "**What this does:** Trains an ensemble of 100 decision trees, each seeing different subsets of data. Predictions are made by majority vote. This reduces overfitting compared to a single tree and often achieves better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d15162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regularization to prevent overfitting\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,          # Reduced from 300 to prevent overfitting\n",
    "    max_depth=10,              # Limit tree depth\n",
    "    min_samples_split=20,      # Require more samples to split\n",
    "    min_samples_leaf=10,       # Require more samples in leaf nodes\n",
    "    max_features='sqrt',       # Use sqrt of features at each split\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'    # Handle class imbalance\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest trained with regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28921b82",
   "metadata": {},
   "source": [
    "## Train Model 4: K-Nearest Neighbors\n",
    "\n",
    "\n",
    "**What this does:** Predicts by finding the 5 most similar training samples and using their majority class. Requires scaled data because it uses distance calculations. Simple but can be effective for well-clustered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73043646",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)  # Use scaled data\n",
    "y_pred_knn = knn.predict(X_test_scaled)  # Use scaled test data\n",
    "\n",
    "print(\"KNN trained with scaled features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bf28a",
   "metadata": {},
   "source": [
    "## Train Model 5: Gradient Boosting (Regularized)\n",
    "\n",
    "\n",
    "**What this does:** Builds trees sequentially where each new tree corrects errors from previous trees. Often achieves highest accuracy but requires careful tuning to prevent overfitting. Regularization parameters control complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f83a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regularization to prevent overfitting\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,               # Limit tree depth\n",
    "    min_samples_split=20,      # Require more samples to split\n",
    "    min_samples_leaf=10,       # Require more samples in leaf nodes\n",
    "    learning_rate=0.1,         # Slower learning for better generalization\n",
    "    subsample=0.8,             # Use 80% of samples for each tree\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting trained with regularization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f80e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter distributions (minimal for speed)\n",
    "param_distributions = {\n",
    "    'n_estimators': [80, 100, 120],      # Fewer trees = faster\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_samples_split': [15, 20],\n",
    "    'min_samples_leaf': [8, 10],\n",
    "    'learning_rate': [0.08, 0.1, 0.12],\n",
    "    'subsample': [0.8]                   # Single value = no search\n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning (8 combinations, 2-fold CV)...\")\n",
    "\n",
    "# ULTRA-FAST configuration\n",
    "random_search = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions,\n",
    "    n_iter=8,              # Only 8 combinations!\n",
    "    cv=2,                  # 2-fold CV = 16 model fits total\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,             # No verbose output for speed\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit and find best parameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"BEST PARAMETERS FOUND:\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"Best CV Accuracy: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "gb_tuned = random_search.best_estimator_\n",
    "y_pred_gb_tuned = gb_tuned.predict(X_test)\n",
    "\n",
    "print(\"Optimized model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0138781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create voting ensemble combining top 3 models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('gb_tuned', gb_tuned),      # Optimized Gradient Boosting (weight=2)\n",
    "        ('rf', rf),                   # Random Forest (weight=1)\n",
    "        ('log_reg', log_reg)          # Logistic Regression (weight=1)\n",
    "    ],\n",
    "    voting='soft',                    # Use probability voting\n",
    "    weights=[2, 1, 1]                 # GB gets double weight (best performer)\n",
    ")\n",
    "\n",
    "print(\"Training ensemble model...\")\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Ensemble trained (GB=50%, RF=25%, LR=25%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47dcda",
   "metadata": {},
   "source": [
    "## Train Model 7: Voting Ensemble\n",
    "\n",
    "Combines Gradient Boosting (50%), Random Forest (25%), and Logistic Regression (25%):\n",
    "\n",
    "\n",
    "**What this does:** Combines predictions from three models using weighted voting. Gradient Boosting gets double weight because it's typically the best performer. This ensemble approach often outperforms individual models by leveraging their different strengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b941b",
   "metadata": {},
   "source": [
    "## Train Model 6: Gradient Boosting (Hyperparameter Tuned)\n",
    "\n",
    "Fast RandomizedSearchCV with 8 combinations × 2-fold CV = 16 fits (~10-20 seconds):\n",
    "\n",
    "\n",
    "**What this does:** Automatically searches for the best hyperparameters by testing 8 random combinations from defined ranges. Uses 2-fold cross-validation for speed while still getting reliable estimates. This often improves accuracy by 2-3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae21a05",
   "metadata": {},
   "source": [
    "## Evaluate All Models\n",
    "\n",
    "Compare performance across all 7 trained models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(\"Logistic Regression (Scaled)\", y_test, y_pred_lr)\n",
    "evaluate_model(\"Decision Tree\", y_test, y_pred_dt)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf)\n",
    "evaluate_model(\"KNN (Scaled)\", y_test, y_pred_knn)\n",
    "evaluate_model(\"Gradient Boosting\", y_test, y_pred_gb)\n",
    "evaluate_model(\"Gradient Boosting (Tuned)\", y_test, y_pred_gb_tuned)\n",
    "evaluate_model(\"Voting Ensemble\", y_test, y_pred_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a993f17",
   "metadata": {},
   "source": [
    "## Compare Model Performance\n",
    "\n",
    "Generate comparison table and visualizations:\n",
    "\n",
    "\n",
    "**What this does:** Evaluates all 7 models using both test accuracy and 5-fold cross-validation. Cross-validation provides more reliable estimates by testing on multiple data splits. The visualizations make it easy to identify the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all models and predictions\n",
    "models = {\n",
    "    'Logistic Regression': (log_reg, y_pred_lr, X_train_scaled),\n",
    "    'Decision Tree': (dt, y_pred_dt, X_train),\n",
    "    'Random Forest': (rf, y_pred_rf, X_train),\n",
    "    'KNN': (knn, y_pred_knn, X_train_scaled),\n",
    "    'Gradient Boosting': (gb, y_pred_gb, X_train),\n",
    "    'GB (Tuned)': (gb_tuned, y_pred_gb_tuned, X_train),\n",
    "    'Voting Ensemble': (voting_clf, y_pred_voting, X_train_scaled)\n",
    "}\n",
    "\n",
    "# Evaluate all models\n",
    "results = []\n",
    "for name, (model, y_pred, X_train_data) in models.items():\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    cv_scores = cross_val_score(model, X_train_data, y_train, cv=5, n_jobs=-1)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(f\"\\nModel Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nBest: {results_df.iloc[0]['Model']} ({results_df.iloc[0]['Test Accuracy']:.4f})\\n\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Test accuracy\n",
    "axes[0].barh(results_df['Model'], results_df['Test Accuracy'])\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_title('Test Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_xlim([0.5, 1.0])\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "axes[1].barh(results_df['Model'], results_df['CV Mean'], color='coral')\n",
    "axes[1].set_xlabel('Accuracy')\n",
    "axes[1].set_title('Cross-Validation Accuracy', fontweight='bold')\n",
    "axes[1].set_xlim([0.5, 1.0])\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "if 'Voting' in best_model_name:\n",
    "    best_model = voting_clf\n",
    "elif 'Tuned' in best_model_name:\n",
    "    best_model = gb_tuned\n",
    "elif 'Gradient' in best_model_name:\n",
    "    best_model = gb\n",
    "elif 'Random' in best_model_name:\n",
    "    best_model = rf\n",
    "else:\n",
    "    best_model = gb_tuned  # Default to tuned GB\n",
    "\n",
    "print(f\"\\nBest model set to: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aafc6c",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Analyze which features are most important for prediction:\n",
    "\n",
    "\n",
    "**What this shows:** Which medical features the model relies on most heavily for predictions. High importance features are the key indicators the model uses to distinguish COVID positive from negative cases. This provides medical insights into disease indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from best model (Gradient Boosting)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance:\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], \n",
    "         color='forestgreen', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontweight='bold', fontsize=12)\n",
    "plt.title('Top 15 Most Important Features for COVID-19 Prediction', \n",
    "          fontweight='bold', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496c0dc",
   "metadata": {},
   "source": [
    "# PART 4: ADVANCED VALIDATION & DEPLOYMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e297f9",
   "metadata": {},
   "source": [
    "## Learning Curves Analysis\n",
    "\n",
    "Visualize training vs validation performance to detect overfitting:\n",
    "\n",
    "\n",
    "**What this shows:** How model performance changes with more training data. A large gap between training and validation curves indicates overfitting (model memorizing training data). Small gap indicates good generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating learning curves...\")\n",
    "# Calculate learning curves\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(train_sizes, train_mean, label='Training Accuracy', \n",
    "         color='blue', marker='o', linewidth=2)\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, val_mean, label='Validation Accuracy (Cross-Val)', \n",
    "         color='red', marker='s', linewidth=2)\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, \n",
    "                 alpha=0.15, color='red')\n",
    "\n",
    "plt.xlabel('Training Set Size', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontweight='bold', fontsize=12)\n",
    "plt.title('Learning Curves - Best Model\\n(Training vs Validation Performance)', fontweight='bold', fontsize=14)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "overfitting_gap = train_mean[-1] - val_mean[-1]\n",
    "print(f\"\\nTrain: {train_mean[-1]:.4f} ± {train_std[-1]:.4f}\")\n",
    "print(f\"Valid: {val_mean[-1]:.4f} ± {val_std[-1]:.4f}\")\n",
    "print(f\"Gap: {overfitting_gap:.4f}\", end=\"\")\n",
    "\n",
    "if overfitting_gap < 0.05:\n",
    "    print(\" (good)\")\n",
    "elif overfitting_gap < 0.10:\n",
    "    print(\" (moderate overfitting)\")\n",
    "else:\n",
    "    print(\" (high overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cab2b2",
   "metadata": {},
   "source": [
    "## 10-Fold Cross-Validation\n",
    "\n",
    "Comprehensive validation using stratified 10-fold CV:\n",
    "\n",
    "\n",
    "**What this does:** Splits data into 10 parts, trains on 9 and tests on 1, rotating through all combinations. This provides more robust performance estimates than a single train-test split by testing on multiple data combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n10-Fold Cross-Validation\")\n",
    "\n",
    "best_model = gb\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(\n",
    "    best_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=skf,\n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Cross-Validation Results (10 Folds):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training Accuracy:   {cv_results['train_accuracy'].mean():.4f} ± {cv_results['train_accuracy'].std():.4f}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Train Acc:  {cv_results['train_accuracy'].mean():.4f} ± {cv_results['train_accuracy'].std():.4f}\")\n",
    "print(f\"Valid Acc:  {cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\")\n",
    "print(f\"Precision:  {cv_results['test_precision'].mean():.4f} ± {cv_results['test_precision'].std():.4f}\")\n",
    "print(f\"Recall:     {cv_results['test_recall'].mean():.4f} ± {cv_results['test_recall'].std():.4f}\")\n",
    "print(f\"F1:         {cv_results['test_f1'].mean():.4f} ± {cv_results['test_f1'].std():.4f}\")\n",
    "\n",
    "overfitting_gap = cv_results['train_accuracy'].mean() - cv_results['test_accuracy'].mean()\n",
    "print(f\"Gap: {overfitting_gap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b47c68",
   "metadata": {},
   "source": [
    "## ROC Curve & AUC Score\n",
    "\n",
    "Evaluate model's discrimination ability:\n",
    "\n",
    "\n",
    "**What this shows:** The model's ability to distinguish between positive and negative cases across all possible thresholds. AUC (Area Under Curve) of 1.0 is perfect, 0.5 is random guessing. Higher AUC means better discrimination ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nROC Analysis\")\n",
    "\n",
    "# Get probability predictions\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=3, \n",
    "         label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random Classifier (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)', fontweight='bold', fontsize=12)\n",
    "plt.title('ROC Curve - COVID-19 Prediction Model', fontweight='bold', fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\\n\")\n",
    "print(\"Interpretation:\")\n",
    "print(f\"\\nAUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb8be2",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis\n",
    "\n",
    "Detailed breakdown of prediction errors (FN are critical in medical diagnosis):\n",
    "\n",
    "\n",
    "**What this shows:** Detailed breakdown of correct and incorrect predictions. In medical diagnosis, False Negatives (missing COVID cases) are most critical as they mean infected patients go untreated. True Positives and True Negatives show correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a171ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced confusion matrix\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', cbar=True,\n",
    "            xticklabels=['COVID Negative (0)', 'COVID Positive (1)'],\n",
    "            yticklabels=['COVID Negative (0)', 'COVID Positive (1)'],\n",
    "            annot_kws={'size': 18, 'weight': 'bold'})\n",
    "plt.title('Confusion Matrix - Final Model', fontweight='bold', fontsize=16)\n",
    "plt.ylabel('Actual Label', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"TN: {tn:,}  FP: {fp:,}\")\n",
    "print(f\"FN: {fn:,}  TP: {tp:,}\")\n",
    "print(f\"\\nSensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f1d690",
   "metadata": {},
   "source": [
    "## Final Performance Summary\n",
    "\n",
    "Comprehensive summary of all validation metrics:\n",
    "\n",
    "\n",
    "**What this shows:** A complete performance report combining all evaluation metrics from previous analyses. This provides a comprehensive view of model quality, reliability, and generalization capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "final_precision = precision_score(y_test, y_pred_final)\n",
    "final_recall = recall_score(y_test, y_pred_final)\n",
    "final_f1 = f1_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"\\nFinal Performance Summary\\n\")\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Test Accuracy',\n",
    "        'Cross-Val Accuracy (10-fold)',\n",
    "        'Precision',\n",
    "        'Recall (Sensitivity)',\n",
    "        'F1-Score',\n",
    "        'Specificity',\n",
    "        'ROC-AUC Score',\n",
    "        'Overfitting Gap'\n",
    "    ],\n",
    "    'Score': [\n",
    "        f\"{final_accuracy:.4f}\",\n",
    "        f\"{cv_results['test_accuracy'].mean():.4f} ± {cv_results['test_accuracy'].std():.4f}\",\n",
    "        f\"{final_precision:.4f}\",\n",
    "        f\"{final_recall:.4f}\",\n",
    "        f\"{final_f1:.4f}\",\n",
    "        f\"{specificity:.4f}\",\n",
    "        f\"{roc_auc:.4f}\",\n",
    "        f\"{overfitting_gap:.4f}\"\n",
    "    ],\n",
    "    'Interpretation': [\n",
    "        f\"{final_accuracy*100:.2f}% correct predictions\",\n",
    "        \"Consistent across 10 folds\",\n",
    "        \"% of positive predictions correct\",\n",
    "        \"% of actual COVID cases detected\",\n",
    "        \"Balance between precision/recall\",\n",
    "        \"% of negatives correctly identified\",\n",
    "        \"Overall discrimination ability\",\n",
    "        \"Generalization quality\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaf57f",
   "metadata": {},
   "source": [
    "## Save Model for Deployment\n",
    "\n",
    "Save best model as .pkl file for production use:\n",
    "\n",
    "\n",
    "**What this does:** Serializes the trained model to a file that can be loaded later for making predictions on new data. This enables deployment in production applications, APIs, or web services without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "MODEL_DIR = \"../model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, \"covid_model.pkl\")\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"Model saved: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
