Ai Project Documentation 
Breast Cancer Prediction Model 
 
Machine Learning Project Documentation 
 
Project Description 
This project presents a complete machine learning pipeline for predicting breast cancer diagnosis 
(malignant vs benign) using cell nuclei characteristics from digitized images of fine needle 
aspirate (FNA) of breast masses. The system includes data preprocessing, exploratory data 
analysis, model training, evaluation, optimization, and deployment preparation, following best 
practices in artificial intelligence and healthcare applications. 
 
Faculty / University 
• Arab Academy for Science, Technology and Maritime Transport 
 
 
Course Code and Name 
• CAI3101 – Introduction to Artificial Intelligence 
 
Course Instructors 
• Dr. Mohamed Ali Abdel-Rabuh Hamouda 
• Eng. Mohamed Moheb Abdel-Sattar Emara 
 
Submitted By 
• Seif Ebeid – ID: 231014746 
• Abdullah Nagy – ID: 231004881 
 
 
 
Ai Project Documentation 
1. Project Overview 
This project presents a complete machine learning system for predicting breast cancer diagnosis 
using cell nuclei characteristics extracted from digitized medical images. The system implements 
an end-to-end pipeline that includes data cleaning, feature engineering, exploratory analysis, 
model training, evaluation, optimization, and deployment preparation. 
Multiple machine learning algorithms are trained and compared to identify the most reliable and 
generalizable model for medical decision support. The project is designed for educational and 
research purposes, with a strong focus on medical validity, feature importance analysis, and 
model robustness. 
 
2. Dataset Information 
The dataset used in this project is the Wisconsin Breast Cancer Diagnostic dataset containing 
measurements from digitized images of breast mass cell nuclei. 
• Source: Wisconsin Breast Cancer Diagnostic Dataset (WBCD) 
• Original Size: 569 samples × 32 columns (30 features + ID + diagnosis) 
• Final Dataset Size: 569 samples (complete, no missing values) 
• Target Variable: 
o diagnosis (Binary Classification) 
o 1 = Malignant (Cancer Present) 
o 0 = Benign (Non-cancerous) 

Features Used 
The model uses 30 numerical features computed from digitized images. Each feature represents 
a characteristic of the cell nucleus, measured in three ways. 

10 Core Cell Nucleus Characteristics: 
Measurement Type      Description 
• radius        Mean distance from center to perimeter 
• texture       Standard deviation of gray-scale values 
• perimeter       Perimeter of the cell nucleus 
• area        Area of the cell nucleus 
• smoothness       Local variation in radius lengths 
• compactness      (perimeter² / area) - 1.0 
• concavity       Severity of concave portions of contour 
• concave points      Number of concave portions of contour 
• symmetry       Symmetry of the cell nucleus 
• fractal dimension      "Coastline approximation" - 1 

Measurement Categories (3 per characteristic = 30 total features): 
• Mean Values (_mean) - Average measurement across all cells 
• Standard Error (_se) - Variability of measurements 
• Worst Values (_worst) - Mean of the three largest values 

3. Data Preprocessing 
Data Loading 
• Complete dataset loaded (569 samples) 
• No sampling needed - dataset is small and clean 
• All 30 features are continuous numerical values 
• Removed any unnamed/empty columns from CSV 

Target Variable Encoding 
• Original Format: M (Malignant) and B (Benign) as strings 
• Encoded Format: M → 1 (positive/cancer), B → 0 (negative/non-cancer) 
• Reason: Machine learning models require numeric targets 

Feature Selection 
• Dropped: id column (patient identifier with no predictive value) 
• Retained: All 30 measurement features 
• No missing values: Dataset is complete and high-quality 

Data Quality Checks 
• Missing Values: 0 (0.0%) 
• Data Types: All numeric (float64) 
• Outliers: Present but medically valid (retained) 
• Class Balance: 357 Benign (63%) vs 212 Malignant (37%) 

4. Exploratory Data Analysis (EDA) 
Target Distribution Analysis 
• Count plot showing malignant vs benign cases 
• Pie chart with percentage distribution 
• Finding: ~63% benign, ~37% malignant (acceptably balanced) 

Correlation Analysis 
• Full correlation matrix of all 30 features 
• Correlation ranking with diagnosis target 
• Key Finding: Highest correlations found in concave_points_worst, perimeter_worst, 
radius_worst 
• Feature groups (radius, perimeter, area) show multicollinearity 

Feature Distribution Comparison 
• Overlapping histograms for top 6 correlated features 
• Benign (green) vs Malignant (red) distributions 
• Finding: Clear separation for "worst" measurement features 

Mean Features Comparison 
• Bar chart comparing all 10 mean features by diagnosis 
• Finding: Malignant tumors consistently show larger values 

5. Feature Scaling 
Normalization Strategy 
• Method: StandardScaler (mean=0, std=1) 
• Applied To: Logistic Regression, KNN, Voting Ensemble 
• Not Applied To: Tree-based models (Decision Tree, Random Forest, Gradient Boosting) 
• Reason: Distance-based algorithms require scaling; tree-based models are scale-invariant 

6. Machine Learning Models 
Train-Test Split 
• Split Ratio: 80% training (455 samples) / 20% testing (114 samples) 
• Stratification: Maintains 63/37 class ratio in both sets 
• Random State: 42 (for reproducibility) 

Models Trained 
Model 1: Logistic Regression (with feature scaling) 
• Linear classification baseline 
• Fast training and inference 
• Interpretable coefficients 
• Use Case: Baseline model when interpretability is important 

Model 2: Decision Tree (regularized) 
• Non-linear decision boundaries 
• Parameters: max_depth=5, min_samples_split=20, min_samples_leaf=10 
• Use Case: Interpretable non-linear patterns 

Model 3: Random Forest (ensemble) 
• 100 trees with regularization 
• Parameters: max_depth=10, min_samples_split=10, min_samples_leaf=5 
• Reduces overfitting via ensemble averaging 
• Use Case: Strong baseline, handles feature interactions 

Model 4: K-Nearest Neighbors (with scaling) 
• Instance-based learning 
• k=5 neighbors 
• Requires scaled features 
• Use Case: Local similarity pattern detection 

Model 5: Gradient Boosting (regularized) 
• Sequential tree building 
• 100 estimators, learning_rate=0.1, max_depth=3 
• Often achieves best performance 
• Use Case: Maximum accuracy priority 

Model 6: Gradient Boosting (hyperparameter tuned) 
• RandomizedSearchCV with 20 iterations × 3-fold CV 
• Automatically finds optimal parameters 
• Parameters searched: n_estimators, learning_rate, max_depth, min_samples_split, 
min_samples_leaf 
• Use Case: Production-ready optimized model 

Model 7: Voting Ensemble (soft voting) 
• Combines Gradient Boosting (weight=2), Random Forest (weight=1), Logistic Regression 
(weight=1) 
• Uses probability averaging 
• Leverages diversity of different model types 
• Use Case: Maximum reliability through ensemble agreement 

7. Model Validation Strategy 
Train-Test Split Validation 
• Single 80/20 split with stratification 
• Provides quick performance estimate 
• Used for initial model comparison 

5-Fold Cross-Validation 
• Used during model comparison 
• Each model trained/tested 5 times on different splits 
• Provides more reliable performance estimates 
• Reports mean ± standard deviation 

10-Fold Cross-Validation 
• Comprehensive validation on best model 
• 10 different train/test combinations 
• Most reliable performance estimate 
• Used for final model evaluation 

Learning Curves Analysis 
• Plots training vs validation accuracy across different training set sizes 
• Detects overfitting (large gap between curves) 
• Interpretation: 
o Gap < 0.05: Good generalization 
o Gap 0.05-0.10: Acceptable 
o Gap > 0.10: Overfitting detected 

ROC Curve & AUC 
• Evaluates discrimination ability across all classification thresholds 
• Interpretation: 
o AUC = 1.0: Perfect classifier 
o AUC = 0.9-1.0: Excellent 
o AUC = 0.8-0.9: Good 
o AUC = 0.7-0.8: Fair 
o AUC = 0.5: Random guessing 

Confusion Matrix Analysis 
• Detailed breakdown of prediction errors 
• Components: 
o True Negatives (TN): Correctly identified benign 
o False Positives (FP): Benign predicted as malignant 
o False Negatives (FN): Malignant predicted as benign (CRITICAL) 
o True Positives (TP): Correctly identified malignant 

8. Feature Importance Analysis 
Method 
• Extracted from Gradient Boosting model 
• Based on how often features are used for splitting 
• Higher values indicate more importance for prediction 

Top Predictive Features (Typical Results) 
1. worst features (radius, perimeter, area) - Largest abnormal measurements 
2. mean features - Average measurements across cells 
3. concave points - Irregularity indicators 
4. texture features - Surface characteristics 

Interpretation 
• Features with high importance are key cancer indicators 
• Medical practitioners can focus on these measurements 
• Validates known medical knowledge about cancer characteristics 

9. Optimization Techniques 
Hyperparameter Tuning 
RandomizedSearchCV was used for efficient hyperparameter optimization, achieving 
performance improvements while maintaining short training times. 

Ensemble Learning 
A soft-voting ensemble combined multiple models to reduce individual model errors and 
improve stability. 

10. Model Performance Summary 
Typically observed performance with Gradient Boosting (best model): 
• Accuracy: 95–98% 
• Precision: 93–97% 
• Recall: 94–98% 
• F1-Score: 94–97% 
• ROC-AUC: 0.98–0.99 
• Overfitting Gap: Less than 5% 
• Cross-Validation Stability: Standard deviation < 0.03 

11. Deployment Guide 
Model Saving 
• Trained model saved as: breast_cancer_model.pkl 
• Scaler saved as: scaler.pkl 
• Both files required for making predictions on new data 

Model Loading & Inference 
1. Load saved model and scaler 
2. Prepare new data (30 features in correct order) 
3. Apply scaling transformation 
4. Make prediction (0=Benign, 1=Malignant) 
5. Obtain probability scores for confidence assessment 

Production Considerations 
• Input validation: Verify 30 features in correct order 
• Missing value handling: Check and validate data quality 
• Scaling: Always use same scaler fitted on training data 
• Threshold adjustment: Can adjust for more conservative predictions 
• Error handling: Implement robust exception handling 

12. Conclusion 
This project demonstrates a complete and medically responsible machine learning pipeline for 
breast cancer diagnosis prediction. Through careful data preprocessing, comprehensive model 
comparison, and rigorous validation, the system achieves excellent performance (95-98% 
accuracy) suitable for educational and research applications. The high recall rates ensure 
minimal missed cancer cases, which is critical in medical diagnosis support systems. 